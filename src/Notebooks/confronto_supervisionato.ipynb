{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import (GridSearchCV, cross_validate,\n",
    "                                     train_test_split)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scripts.get_data import ceramiche_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Neural net\": (\n",
    "                MLPClassifier(),\n",
    "                {\n",
    "                    'hidden_layer_sizes': list(range(2,30)),\n",
    "                    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                }\n",
    "            ),\n",
    "\n",
    "\n",
    "    \"Nearest Neighbors\": (\n",
    "                    KNeighborsClassifier(),\n",
    "                    {\n",
    "                        'n_neighbors': list(range(1,11)), \n",
    "                        'weights': ['uniform', 'distance']\n",
    "                    }\n",
    "                ),\n",
    "    \"SVC\": (\n",
    "                    SVC(),\n",
    "                    [{\n",
    "                        'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "                        'C': [x/10 for x in range(1, 11)],\n",
    "                    },\n",
    "                    {\n",
    "                        'kernel': ['poly'],\n",
    "                        'degree': list(range(2,6)),\n",
    "                        'C': [x/10 for x in range(1, 11)],\n",
    "                    }]\n",
    "                ),\n",
    "    \"Decision Tree\": (\n",
    "                    DecisionTreeClassifier(),\n",
    "                    {\n",
    "                        'criterion': ['gini', 'entropy'], \n",
    "                        'min_samples_split':list(range(2,11)),\n",
    "                        'min_samples_leaf': list(range(1,6)),\n",
    "                    }\n",
    "                ),\n",
    "    \"Random Forest\": (\n",
    "                    RandomForestClassifier(n_jobs=-1),\n",
    "                    {\n",
    "                        'n_estimators': list(range(1, 101, 10)), \n",
    "                        'criterion': ['gini', 'entropy'], \n",
    "                        'min_samples_split':list(range(2, 11)),\n",
    "                        'min_samples_leaf': list(range(1, 6)),\n",
    "                        'oob_score': [True, False],\n",
    "                    }\n",
    "                ),\n",
    "    \"Naive Bayes\": (\n",
    "                    GaussianNB(),\n",
    "                    {}\n",
    "                ),\n",
    "\n",
    "    # \"Gaussian Process\": GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    # \"AdaBoost\": AdaBoostClassifier(),\n",
    "    # \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensibility(y_true, y_predict):\n",
    "    c_matrix = confusion_matrix(y_true, y_predict)\n",
    "    return c_matrix[1][1]/sum(c_matrix[1])\n",
    "\n",
    "\n",
    "def specificity(y_true, y_predict):\n",
    "    c_matrix = confusion_matrix(y_true, y_predict)\n",
    "    return c_matrix[0][0]/sum(c_matrix[0])\n",
    "\n",
    "\n",
    "scores = {\n",
    "    'sensibility' : make_scorer(sensibility, greater_is_better=True),\n",
    "    'specificity' : make_scorer(specificity, greater_is_better=True),\n",
    "    'accuracy' : make_scorer(accuracy_score, greater_is_better=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Excel xlsx file; not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-50fbed9ec4cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mceramiche_DB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# X_train, X_test, y_train, y_test = train_test_split(X, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/tirocinio-reperti-archeologici/src/scripts/get_data.py\u001b[0m in \u001b[0;36mceramiche_DB\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'dati_ceramiche_classi.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     tarquina = pd.read_excel(path, index_col=0, usecols=[\n\u001b[0;32m----> 8\u001b[0;31m                              0, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     non_tarquina = pd.read_excel(path, index_col=0, usecols=[\n",
      "\u001b[0;32m~/GitHub/tirocinio-reperti-archeologici/tirocinio3.7-venv/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/tirocinio-reperti-archeologici/tirocinio3.7-venv/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mNA\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthousands\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mexplicitly\u001b[0m \u001b[0mspecified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoo\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mSupply\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m \u001b[0;32mas\u001b[0m \u001b[0mstrings\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlists\u001b[0m \u001b[0mof\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;31m!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m >>> pd.read_excel('tmp.xlsx', index_col=0,\n",
      "\u001b[0;32m~/GitHub/tirocinio-reperti-archeologici/tirocinio3.7-venv/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, engine)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;31m# only switch class if generic(ExcelWriter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/tirocinio-reperti-archeologici/tirocinio3.7-venv/lib/python3.7/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mObject\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mstorage_options\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mfsspec\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mappropriate\u001b[0m \u001b[0mURLs\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_get_filepath_or_buffer\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \"\"\"\n\u001b[1;32m     23\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/tirocinio-reperti-archeologici/tirocinio3.7-venv/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0mstorage_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStorageOptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m ):\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/tirocinio-reperti-archeologici/tirocinio3.7-venv/lib/python3.7/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mxlrd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/tirocinio-reperti-archeologici/tirocinio3.7-venv/lib/python3.7/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# files that xlrd can parse don't start with the expected signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'xls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE_FORMAT_DESCRIPTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'; not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     bk = open_workbook_xls(\n",
      "\u001b[0;31mXLRDError\u001b[0m: Excel xlsx file; not supported"
     ]
    }
   ],
   "source": [
    "X, y = ceramiche_DB()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se voi eseguire di nuovo la computazione invece che caricare quella cacheata cambia questa variabile\n",
    "NEW_COMPUTATION = False\n",
    "\n",
    "if NEW_COMPUTATION:\n",
    "    result = {}\n",
    "\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        for name, (clf, params) in tqdm(classifiers.items()):\n",
    "            grid = GridSearchCV(clf, params, scoring='accuracy', cv = 5, n_jobs = -1)\n",
    "            s = cross_validate(grid, X, y, cv=5, scoring = scores, return_estimator=True)\n",
    "            result[name] = s\n",
    "else:\n",
    "    result = load('../scripts/supervised_dump.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEURAL NET\n",
      "                mean       std\n",
      "      sens    0.9287     0.114\n",
      "      spec       0.8    0.1633\n",
      "      accu    0.8947   0.06795\n",
      "\n",
      "\n",
      "NEAREST NEIGHBORS\n",
      "                mean       std\n",
      "      sens    0.9522   0.06874\n",
      "      spec    0.9333    0.1333\n",
      "      accu    0.9477   0.04959\n",
      "\n",
      "\n",
      "SVC\n",
      "                mean       std\n",
      "      sens    0.9404   0.09114\n",
      "      spec    0.8667    0.1633\n",
      "      accu    0.9212   0.05538\n",
      "\n",
      "\n",
      "DECISION TREE\n",
      "                mean       std\n",
      "      sens    0.9037    0.1227\n",
      "      spec    0.9333    0.1333\n",
      "      accu    0.9129   0.08039\n",
      "\n",
      "\n",
      "RANDOM FOREST\n",
      "                mean       std\n",
      "      sens       1.0       0.0\n",
      "      spec    0.9333    0.1333\n",
      "      accu    0.9818   0.03636\n",
      "\n",
      "\n",
      "NAIVE BAYES\n",
      "                mean       std\n",
      "      sens       1.0       0.0\n",
      "      spec       1.0       0.0\n",
      "      accu       1.0       0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = ['sensibility', 'specificity', 'accuracy'] #score.keys()\n",
    "columns = ['mean', 'std']\n",
    "\n",
    "row_format =\"{:>10.4}\" * (len(columns) + 1)\n",
    "col_format =\"{:>10.4}\" * (len(columns) + 1)\n",
    "\n",
    "for n, r in result.items():\n",
    "    print(n.upper())\n",
    "\n",
    "    data = [(r[\"test_\"+x].mean(), r[\"test_\"+x].std()) for x in rows]\n",
    "\n",
    "    print(col_format.format(\"\", *columns))\n",
    "    for name, row in zip(rows, data):\n",
    "        print(row_format.format(name, *row))\n",
    "\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(result, '../scripts/supervised_dump.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da84ec820d139cc4ab1ee37f452e45ec5df814a0c2afc50bf079a89a180f74df"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
