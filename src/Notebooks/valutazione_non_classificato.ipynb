{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bittirociniovenv84d0edb410514e668b85d5e5e766f942",
   "display_name": "Python 3.8.5 64-bit ('tirocinio-venv')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "from scripts.get_data import da_classificare_DB\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "Created on Aug 1, 2016\n",
    "@author: skarumbaiah\n",
    "Computes Fleiss' Kappa \n",
    "Joseph L. Fleiss, Measuring Nominal Scale Agreement Among Many Raters, 1971.\n",
    "'''\n",
    "\n",
    "def fleissKappa(rate,n):\n",
    "    \"\"\" \n",
    "    Computes the Kappa value\n",
    "    @param rate - ratings matrix containing number of ratings for each subject per category \n",
    "    [size - N X k where N = #subjects and k = #categories]\n",
    "    @param n - number of raters   \n",
    "    @return fleiss' kappa\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(rate)\n",
    "    k = len(rate[0])\n",
    "    print(\"#raters = \", n, \", #subjects = \", N, \", #categories = \", k)\n",
    "    \n",
    "    #mean of the extent to which raters agree for the ith subject \n",
    "    PA = sum([(sum([i**2 for i in row])- n) / (n * (n - 1)) for row in rate])/N\n",
    "    print(\"PA = \", PA)\n",
    "    \n",
    "    # mean of squares of proportion of all assignments which were to jth category\n",
    "    PE = sum([j**2 for j in [sum([rows[i] for rows in rate])/(N*n) for i in range(k)]])\n",
    "    print(\"PE =\", PE)\n",
    "    \n",
    "    kappa = -float(\"inf\")\n",
    "    try:\n",
    "        kappa = (PA - PE) / (1 - PE)\n",
    "        kappa = float(\"{:.3f}\".format(kappa))\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Expected agreement = 1\")\n",
    "\n",
    "    print(\"Fleiss' Kappa =\", kappa)\n",
    "    \n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- coding: utf-8\n",
    "'''\n",
    "Python implementation of Krippendorff's alpha -- inter-rater reliability\n",
    "(c)2011-17 Thomas Grill (http://grrrr.org)\n",
    "Python version >= 2.4 required\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "try:\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    np = None\n",
    "\n",
    "\n",
    "def nominal_metric(a, b):\n",
    "    return a != b\n",
    "\n",
    "\n",
    "def interval_metric(a, b):\n",
    "    return (a-b)**2\n",
    "\n",
    "\n",
    "def ratio_metric(a, b):\n",
    "    return ((a-b)/(a+b))**2\n",
    "\n",
    "\n",
    "def krippendorff_alpha(data, metric=interval_metric, force_vecmath=False, convert_items=float, missing_items=None):\n",
    "    '''\n",
    "    Calculate Krippendorff's alpha (inter-rater reliability):\n",
    "    \n",
    "    data is in the format\n",
    "    [\n",
    "        {unit1:value, unit2:value, ...},  # coder 1\n",
    "        {unit1:value, unit3:value, ...},   # coder 2\n",
    "        ...                            # more coders\n",
    "    ]\n",
    "    or \n",
    "    it is a sequence of (masked) sequences (list, numpy.array, numpy.ma.array, e.g.) with rows corresponding to coders and columns to items\n",
    "    \n",
    "    metric: function calculating the pairwise distance\n",
    "    force_vecmath: force vector math for custom metrics (numpy required)\n",
    "    convert_items: function for the type conversion of items (default: float)\n",
    "    missing_items: indicator for missing items (default: None)\n",
    "    '''\n",
    "    \n",
    "    # number of coders\n",
    "    m = len(data)\n",
    "    \n",
    "    # set of constants identifying missing values\n",
    "    if missing_items is None:\n",
    "        maskitems = []\n",
    "    else:\n",
    "        maskitems = list(missing_items)\n",
    "    if np is not None:\n",
    "        maskitems.append(np.ma.masked_singleton)\n",
    "    \n",
    "    # convert input data to a dict of items\n",
    "    units = {}\n",
    "    for d in data:\n",
    "        try:\n",
    "            # try if d behaves as a dict\n",
    "            diter = d.items()\n",
    "        except AttributeError:\n",
    "            # sequence assumed for d\n",
    "            diter = enumerate(d)\n",
    "            \n",
    "        for it, g in diter:\n",
    "            if g not in maskitems:\n",
    "                try:\n",
    "                    its = units[it]\n",
    "                except KeyError:\n",
    "                    its = []\n",
    "                    units[it] = its\n",
    "                its.append(convert_items(g))\n",
    "\n",
    "\n",
    "    units = dict((it, d) for it, d in units.items() if len(d) > 1)  # units with pairable values\n",
    "    n = sum(len(pv) for pv in units.values())  # number of pairable values\n",
    "    \n",
    "    if n == 0:\n",
    "        raise ValueError(\"No items to compare.\")\n",
    "    \n",
    "    np_metric = (np is not None) and ((metric in (interval_metric, nominal_metric, ratio_metric)) or force_vecmath)\n",
    "    \n",
    "    Do = 0.\n",
    "    for grades in units.values():\n",
    "        if np_metric:\n",
    "            gr = np.asarray(grades)\n",
    "            Du = sum(np.sum(metric(gr, gri)) for gri in gr)\n",
    "        else:\n",
    "            Du = sum(metric(gi, gj) for gi in grades for gj in grades)\n",
    "        Do += Du/float(len(grades)-1)\n",
    "    Do /= float(n)\n",
    "\n",
    "    if Do == 0:\n",
    "        return 1.\n",
    "\n",
    "    De = 0.\n",
    "    for g1 in units.values():\n",
    "        if np_metric:\n",
    "            d1 = np.asarray(g1)\n",
    "            for g2 in units.values():\n",
    "                De += sum(np.sum(metric(d1, gj)) for gj in g2)\n",
    "        else:\n",
    "            for g2 in units.values():\n",
    "                De += sum(metric(gi, gj) for gi in g1 for gj in g2)\n",
    "    De /= float(n*(n-1))\n",
    "\n",
    "    return 1.-Do/De if (Do and De) else 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.neural_network.multilayer_perceptron'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1a513258e33a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mda_classificare_DB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../scripts/supervised_dump.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclassified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dati_ceramiche_classificati.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/tirocinio/tirocinio-venv/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/tirocinio/tirocinio-venv/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1208\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mload_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1527\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_compat_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMPORT_MAPPING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compat_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMPORT_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.neural_network.multilayer_perceptron'"
     ]
    }
   ],
   "source": [
    "X = da_classificare_DB()\n",
    "\n",
    "results = load('../scripts/supervised_dump.joblib')\n",
    "\n",
    "classified = pd.read_excel('../dati_ceramiche_classificati.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Neural net        : 0.053\nNearest Neighbors : 0.053\nSVC               : -0.015\nDecision Tree     : -0.152\nRandom Forest     : -0.061\nNaive Bayes       : -0.341\nvalutazione       : 0.000\n"
     ]
    }
   ],
   "source": [
    "for c in classified.iloc[:, 13:-1]:\n",
    "    err = sum([x[0]-x[1] for x in zip(classified[c], classified['valutazione'])])\n",
    "    print(f'{c:<18}'+':', f'{ err / len(classified) :>4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs = dict()\n",
    "for k, v in results.items():\n",
    "    cfs[k] = max(\n",
    "            zip(v['test_accuracy'], v['estimator']),\n",
    "            key= lambda x: x[0]\n",
    "        ) [1].best_estimator_ "
   ]
  },
  {
   "source": [
    "# Inter modello"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#raters =  6 , #subjects =  132 , #categories =  2\nPA =  0.7883838383838391\nPE = 0.5026814865830018\nFleiss' Kappa = 0.574\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.574"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "y = []\n",
    "for x in zip(*[c.predict(X) for c in cfs.values()]):\n",
    "    n = sum(x)\n",
    "    y.append([6-n, n])\n",
    "fleissKappa(y, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5750229203397981"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "krippendorff_alpha([c.predict(X) for c in cfs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'classified' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3c8985adcc41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassified\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassified\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classified' is not defined"
     ]
    }
   ],
   "source": [
    "## Calcola le medie degli stimatori, le scala secondo una parabola (y = 4x^2 -4x + 1)\n",
    "# che passa per i punti: (0,1), (0.5, 0) (1, 1) e poi calcola la media di queste\n",
    "#  \n",
    "#\n",
    "sum([4*x**2 -4*x + 1 for x in [sum(c)/6 for _, c in classified.iloc[:, -7:-1].iterrows()]])/len(classified)"
   ]
  },
  {
   "source": [
    "# Intra modello"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = {\n",
    "    'Neural net': [],\n",
    "    'Nearest Neighbors': [],\n",
    "    'SVC': [],\n",
    "    'Decision Tree': [],\n",
    "    'Random Forest': [],\n",
    "    'Naive Bayes': [],\n",
    "    'valutazione': [],\n",
    "}\n",
    "for _, row in classified.iterrows():\n",
    "\n",
    "    if pd.isna(row['Campione']):\n",
    "        for k, v in split.items():\n",
    "            v[-1].append(row[k])\n",
    "    else:\n",
    "        for k, v in split.items():\n",
    "            v.append([row[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Neural net           -> 0.07505\nNearest Neighbors    -> 0.06678\nSVC                  -> 0.06366\nDecision Tree        -> 0.07718\nRandom Forest        -> 0.08791\nNaive Bayes          -> 0.06236\nvalutazione          -> 0.04273\n"
     ]
    }
   ],
   "source": [
    "# media delle deviazione standard delle classificazioni all'interno dello reperto\n",
    "for k in split:\n",
    "    std = np.mean([np.std(x) for x in split[k] if len(x)>1]) \n",
    "    print(f'{k:<20} -> {std:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}