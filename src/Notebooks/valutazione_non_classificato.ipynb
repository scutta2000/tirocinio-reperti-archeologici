{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "tirocinio",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "from scripts.get_data import da_classificare_DB\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "Created on Aug 1, 2016\n",
    "@author: skarumbaiah\n",
    "Computes Fleiss' Kappa \n",
    "Joseph L. Fleiss, Measuring Nominal Scale Agreement Among Many Raters, 1971.\n",
    "'''\n",
    "\n",
    "def fleissKappa(rate,n):\n",
    "    \"\"\" \n",
    "    Computes the Kappa value\n",
    "    @param rate - ratings matrix containing number of ratings for each subject per category \n",
    "    [size - N X k where N = #subjects and k = #categories]\n",
    "    @param n - number of raters   \n",
    "    @return fleiss' kappa\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(rate)\n",
    "    k = len(rate[0])\n",
    "    print(\"#raters = \", n, \", #subjects = \", N, \", #categories = \", k)\n",
    "    \n",
    "    #mean of the extent to which raters agree for the ith subject \n",
    "    PA = sum([(sum([i**2 for i in row])- n) / (n * (n - 1)) for row in rate])/N\n",
    "    print(\"PA = \", PA)\n",
    "    \n",
    "    # mean of squares of proportion of all assignments which were to jth category\n",
    "    PE = sum([j**2 for j in [sum([rows[i] for rows in rate])/(N*n) for i in range(k)]])\n",
    "    print(\"PE =\", PE)\n",
    "    \n",
    "    kappa = -float(\"inf\")\n",
    "    try:\n",
    "        kappa = (PA - PE) / (1 - PE)\n",
    "        kappa = float(\"{:.3f}\".format(kappa))\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Expected agreement = 1\")\n",
    "\n",
    "    print(\"Fleiss' Kappa =\", kappa)\n",
    "    \n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- coding: utf-8\n",
    "'''\n",
    "Python implementation of Krippendorff's alpha -- inter-rater reliability\n",
    "(c)2011-17 Thomas Grill (http://grrrr.org)\n",
    "Python version >= 2.4 required\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "try:\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    np = None\n",
    "\n",
    "\n",
    "def nominal_metric(a, b):\n",
    "    return a != b\n",
    "\n",
    "\n",
    "def interval_metric(a, b):\n",
    "    return (a-b)**2\n",
    "\n",
    "\n",
    "def ratio_metric(a, b):\n",
    "    return ((a-b)/(a+b))**2\n",
    "\n",
    "\n",
    "def krippendorff_alpha(data, metric=interval_metric, force_vecmath=False, convert_items=float, missing_items=None):\n",
    "    '''\n",
    "    Calculate Krippendorff's alpha (inter-rater reliability):\n",
    "    \n",
    "    data is in the format\n",
    "    [\n",
    "        {unit1:value, unit2:value, ...},  # coder 1\n",
    "        {unit1:value, unit3:value, ...},   # coder 2\n",
    "        ...                            # more coders\n",
    "    ]\n",
    "    or \n",
    "    it is a sequence of (masked) sequences (list, numpy.array, numpy.ma.array, e.g.) with rows corresponding to coders and columns to items\n",
    "    \n",
    "    metric: function calculating the pairwise distance\n",
    "    force_vecmath: force vector math for custom metrics (numpy required)\n",
    "    convert_items: function for the type conversion of items (default: float)\n",
    "    missing_items: indicator for missing items (default: None)\n",
    "    '''\n",
    "    \n",
    "    # number of coders\n",
    "    m = len(data)\n",
    "    \n",
    "    # set of constants identifying missing values\n",
    "    if missing_items is None:\n",
    "        maskitems = []\n",
    "    else:\n",
    "        maskitems = list(missing_items)\n",
    "    if np is not None:\n",
    "        maskitems.append(np.ma.masked_singleton)\n",
    "    \n",
    "    # convert input data to a dict of items\n",
    "    units = {}\n",
    "    for d in data:\n",
    "        try:\n",
    "            # try if d behaves as a dict\n",
    "            diter = d.items()\n",
    "        except AttributeError:\n",
    "            # sequence assumed for d\n",
    "            diter = enumerate(d)\n",
    "            \n",
    "        for it, g in diter:\n",
    "            if g not in maskitems:\n",
    "                try:\n",
    "                    its = units[it]\n",
    "                except KeyError:\n",
    "                    its = []\n",
    "                    units[it] = its\n",
    "                its.append(convert_items(g))\n",
    "\n",
    "\n",
    "    units = dict((it, d) for it, d in units.items() if len(d) > 1)  # units with pairable values\n",
    "    n = sum(len(pv) for pv in units.values())  # number of pairable values\n",
    "    \n",
    "    if n == 0:\n",
    "        raise ValueError(\"No items to compare.\")\n",
    "    \n",
    "    np_metric = (np is not None) and ((metric in (interval_metric, nominal_metric, ratio_metric)) or force_vecmath)\n",
    "    \n",
    "    Do = 0.\n",
    "    for grades in units.values():\n",
    "        if np_metric:\n",
    "            gr = np.asarray(grades)\n",
    "            Du = sum(np.sum(metric(gr, gri)) for gri in gr)\n",
    "        else:\n",
    "            Du = sum(metric(gi, gj) for gi in grades for gj in grades)\n",
    "        Do += Du/float(len(grades)-1)\n",
    "    Do /= float(n)\n",
    "\n",
    "    if Do == 0:\n",
    "        return 1.\n",
    "\n",
    "    De = 0.\n",
    "    for g1 in units.values():\n",
    "        if np_metric:\n",
    "            d1 = np.asarray(g1)\n",
    "            for g2 in units.values():\n",
    "                De += sum(np.sum(metric(d1, gj)) for gj in g2)\n",
    "        else:\n",
    "            for g2 in units.values():\n",
    "                De += sum(metric(gi, gj) for gi in g1 for gj in g2)\n",
    "    De /= float(n*(n-1))\n",
    "\n",
    "    return 1.-Do/De if (Do and De) else 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = da_classificare_DB()\n",
    "\n",
    "results = load('../scripts/supervised_dump.joblib')\n",
    "\n",
    "classified = pd.read_excel('../dati_ceramiche_classificati.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Neural net        : 0.130\nNearest Neighbors : 0.130\nSVC               : 0.062\nDecision Tree     : -0.074\nRandom Forest     : 0.016\nNaive Bayes       : -0.264\n"
     ]
    }
   ],
   "source": [
    "for c in classified.iloc[:, 13:-1]:\n",
    "    err = sum([x[0]-x[1] for x in zip(classified[c], classified['media'])])\n",
    "    print(f'{c:<18}'+':', f'{ err / len(classified) :>4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs = dict()\n",
    "for k, v in results.items():\n",
    "    cfs[k] = max(\n",
    "            zip(v['test_accuracy'], v['estimator']),\n",
    "            key= lambda x: x[0]\n",
    "        ) [1].best_estimator_ "
   ]
  },
  {
   "source": [
    "# Inter modello"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#raters =  6 , #subjects =  132 , #categories =  2\nPA =  0.7883838383838391\nPE = 0.5026814865830018\nFleiss' Kappa = 0.574\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.574"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "y = []\n",
    "for x in zip(*[c.predict(X) for c in cfs.values()]):\n",
    "    n = sum(x)\n",
    "    y.append([6-n, n])\n",
    "fleissKappa(y, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5750229203397981"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "krippendorff_alpha([c.predict(X) for c in cfs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6473063973063974"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "## Calcola le medie degli stimatori, le scala secondo una parabola (y = 4x^2 -4x + 1)\r\n",
    "# che passa per i punti: (0,1), (0.5, 0) (1, 1) e poi calcola la media di queste\r\n",
    "#  \r\n",
    "#\r\n",
    "sum([4*x**2 -4*x + 1 for x in [sum(c)/6 for _, c in classified.iloc[:, -7:-1].iterrows()]])/len(classified)"
   ]
  },
  {
   "source": [
    "# Intra modello"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = {\n",
    "    'Neural net': [],\n",
    "    'Nearest Neighbors': [],\n",
    "    'SVC': [],\n",
    "    'Decision Tree': [],\n",
    "    'Random Forest': [],\n",
    "    'Naive Bayes': [],\n",
    "}\n",
    "for _, row in classified.iterrows():\n",
    "    # print(pd.isna(row['Campione']))\n",
    "\n",
    "    if pd.isna(row['Campione']):\n",
    "        for k, v in split.items():\n",
    "            v[-1].append(row[k])\n",
    "    else:\n",
    "        for k, v in split.items():\n",
    "            v.append([row[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Neural net           -> 0.07505\nNearest Neighbors    -> 0.06678\nSVC                  -> 0.06366\nDecision Tree        -> 0.07718\nRandom Forest        -> 0.08791\nNaive Bayes          -> 0.06236\n"
     ]
    }
   ],
   "source": [
    "# media delle deviazione standard delle classificazioni all'interno dello reperto\n",
    "for k in split:\n",
    "    std = np.mean([np.std(x) for x in split[k] if len(x)>1]) \n",
    "    print(f'{k:<20} -> {std:.4}')"
   ]
  }
 ]
}